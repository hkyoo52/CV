## 사용처
* AR, VR
* 3D 프린터
* 의료, 화학

## 2D->3D

* 카메라는 projection 해서 보여줌
* 2개 이상의 projection 존재하면 3D로 구현 가능
* 책 : Multiple View Geometry 추천

## 3D data representaion
1. Multi-view : 다양한 각도로 저장
2. Volumetric(voxel) : voxel로 나눠서 표현
3. Part assembly : 여러 집합으로 나눠서 표현
4. Point cloud : (x,y,z)로 저장해서 표현
5. Mesh : (x,y,z)좌표(vertex)와 각 좌표를 잇는 직선(edge)로 표현
6. Implicit shape : 고차원의 함수로 표현

![image](https://user-images.githubusercontent.com/63588046/158506258-dc622d18-4243-4499-8fbe-c2a104f709d9.png)


## 주요 데이터셋
#### PartNet
* 유용하게 segementation해서 저장해논 데이터

![image](https://user-images.githubusercontent.com/63588046/158506548-75c330f1-9a81-44c1-9d71-049760234905.png)


#### SceneNet
* RGB-Depth 실내 데이터

#### ScanNet
* RGB-Depth 실제로 scan한 데이터

#### Kitti, Waymo Open Dataset
* 자율주행용 데이터셋



## 3D recognition
* 3D Model CNN해서 인식 (Volumetric CNN)

## 3D object detection
#### Mesh R-CNN
* input : 2D image
* output : 3D mesh
* mask RCNN 사용

![image](https://user-images.githubusercontent.com/63588046/158514553-2fedb185-4673-47a1-93a7-ac19de7e8cb3.png)

![image](https://user-images.githubusercontent.com/63588046/158514685-73f126f2-cab4-476c-bec6-ebb08ecd4bb4.png)

## Conditional 3D generation
* 3d object 구조를 sub problem으로 분해 (depth, mask, surfce 등등 출력) -> 3D shape 

![image](https://user-images.githubusercontent.com/63588046/158514959-f8527284-af5b-4a5b-97c6-e7a844002191.png)



## Defocusing
* focus 할 지점의 depth 임계값 정함     Ex. 170
* focus 할 것과 defocusing 할 것 정해서 mask함
* input image에 blurred version 생성     # kernel size 20,20 사용 
* Masked focused image, Masked defocused image 계산
* 2개 blending(합침)

=> 영상 참고!!!

























