## AI 모델 성능
#### AI = 구조 + 데이터 + 최적화

![image](https://user-images.githubusercontent.com/63588046/162654841-e37bcba5-59af-4ceb-924c-5196908e3c55.png)




## Software 1.0
* 인공지능 사용 X 소프트웨어
* 사람이 개입을 해서 특징 얻음
#### 문제 정의
* EX. 비디오를 고화질로 촬용하면 용량이 점점 커지는데 적은 용량으로 품질 저하 없이 저장 가능할까?
* A. 적은 용량으로 저장하고 재생할때 복원하자

#### 큰 문제를 작은 문제들의 집합으로 분해
* 분해 할 수 잇는 여러가지 방법 찾기 등등

#### 개별 문제별로 알고리즘 설계

#### 솔류션들을 합쳐 하나의 시스템으로 만듬



## Software 2.0
* 인공지능 사용
* 사람이 개입하지 않음

#### 학습 방법
* 모델 구조로 프로그램 검색 범위 한정
* 데이터와 최적화 방법을 토해 최적의 프로그램 찾는다



## AI Research
![image](https://user-images.githubusercontent.com/63588046/162665456-d7079746-2219-44e9-bc7f-529893f8aa6c.png)


## AI Production
* 데이터셋 없는 경우 많음
* 테스트 방법도 없는 경우 많음
* 요구사항만 존재

![image](https://user-images.githubusercontent.com/63588046/162665555-2d444026-37b1-4c4c-851c-b2eceb21f7b4.png)

#### AI 모델 개발 과정
1. Project Setup
  * 모델 요구사항 확정
  * 처리시간
  * 목표 정확도
  * 목표 qps (초당 처리 가능한 양)
  * Serving 방식
  * 장비 사양
2. Data Preparation
  * 데이터셋 준비
    * 종류
    * 수량
    * 정답
3. Model Training
  * 모델 학습 및 디버깅
    * 데이터 관련 피드백
    * 요구사항 달성

4. Deployging (실제로 서비스 제공)
  * 설치 및 유지보수

#### 성능 향상 방법
* 데이터의 힘 (특히 서비스 만든 이후의 성능 향상은 데이터의 힘이 중요(모델을 바꾸면 qps, 장비 기능 등등 다양한 문제점 발생 가능성 있음)
* 모델 구조/학습 방법


## 데이터 관련 업무가 많은 이유
* 데이터 관련 논문이 매우 적음
* 라벨링 작업이 생각보다 많이 어렵다 (희귀한 데이터는 사람마다 라벨링을 다르게 함...)

![image](https://user-images.githubusercontent.com/63588046/162667113-234e4c7a-bdcc-48a1-8854-bf27e97d0911.png)
![image](https://user-images.githubusercontent.com/63588046/162667230-21ef0794-2b88-49e2-a841-96e266ead32c.png)

* 데이터 불균형을 잡기가 여렵다
 * 골고루 일정하게 라벨링된 데이터가 많아야하는데...
 * 특이한 데이터는 적다... (모으기 어려움)



## Software 2.0 IDE가 가져야하는 기능

1. 데이터셋 시각화
 * 데이터/레이블 분포 시각화
 * 레이블 시각화
 * 데이터 별 예측값 시각화

2. 데이터 라벨링
 * 레이블 UI
 * 테스크 특화 기능
 * 라벨링 일관성 확인
 * 자동 라벨링

3. 데이터셋 정제
 * 반복 데이터 제거
 * 라벨링 오류 수정

4. 데이터셋 선별
 * 라벨링 안된 데이터가 엄청 많음
 * 어떤 데이터를 가지고 와야 성능 향상을 위해서 라벨링을 하나?
